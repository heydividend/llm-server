#!/usr/bin/env python3
"""
ML-Enhanced Portfolio Optimization
Combines Mean-Variance Optimization with LSTM predictions and CVaR constraints
Based on MIT 2024 research showing CNN-LSTM portfolios beat market indices
"""

import argparse
import json
import os
import sys
import warnings
from typing import Dict, List, Tuple, Any, Optional

warnings.filterwarnings('ignore')

try:
    import pandas as pd
    import numpy as np
    from scipy.optimize import minimize
    from sklearn.covariance import LedoitWolf
    import joblib
except ImportError as e:
    print(f"Error importing required packages: {e}")
    sys.exit(1)


class MLPortfolioOptimizer:
    """
    Advanced portfolio optimization using ML-enhanced expected returns
    Implements Mean-Variance, CVaR, and entropy-based diversification
    """
    
    def __init__(self, risk_aversion: float = 2.5):
        """
        Args:
            risk_aversion: Risk aversion coefficient (higher = more conservative)
        """
        self.risk_aversion = risk_aversion
        self.expected_returns = None
        self.covariance_matrix = None
        self.constraints = []
        self.bounds = []
        
    def prepare_data(self, holdings_data: List[Dict]) -> pd.DataFrame:
        """Prepare portfolio data with historical returns"""
        print(f"üìä Preparing portfolio data for {len(holdings_data)} holdings...")
        
        df = pd.DataFrame(holdings_data)
        
        # Required columns: symbol, returns (time series), current_weight
        if 'returns' not in df.columns:
            raise ValueError("Holdings data must include historical returns")
        
        return df
    
    def estimate_expected_returns(
        self, 
        historical_returns: pd.DataFrame,
        ml_predictions: Optional[Dict] = None
    ) -> np.ndarray:
        """
        Estimate expected returns using hybrid approach
        
        Args:
            historical_returns: Historical return matrix (T x N)
            ml_predictions: Optional ML model predictions for future returns
            
        Returns:
            Expected returns vector
        """
        print("üìà Estimating expected returns...")
        
        # Historical mean returns
        historical_mean = historical_returns.mean()
        
        if ml_predictions:
            # Combine historical with ML predictions (Bayesian approach)
            ml_mean = pd.Series(ml_predictions)
            
            # Weight: 60% ML predictions, 40% historical (research-based)
            expected_returns = 0.6 * ml_mean + 0.4 * historical_mean
        else:
            # Fallback to historical with shrinkage
            overall_mean = historical_mean.mean()
            shrinkage_factor = 0.3
            expected_returns = (1 - shrinkage_factor) * historical_mean + shrinkage_factor * overall_mean
        
        self.expected_returns = expected_returns.values
        return self.expected_returns
    
    def estimate_covariance_matrix(self, historical_returns: pd.DataFrame) -> np.ndarray:
        """
        Estimate covariance matrix using Ledoit-Wolf shrinkage
        More stable than sample covariance for small samples
        """
        print("üìä Estimating covariance matrix with Ledoit-Wolf shrinkage...")
        
        lw = LedoitWolf()
        self.covariance_matrix = lw.fit(historical_returns).covariance_
        
        return self.covariance_matrix
    
    def optimize_mean_variance(
        self,
        expected_returns: np.ndarray,
        cov_matrix: np.ndarray,
        constraints: Dict[str, Any]
    ) -> Dict:
        """
        Mean-Variance Optimization (Markowitz)
        
        Args:
            expected_returns: Expected return vector
            cov_matrix: Covariance matrix
            constraints: Optimization constraints
            
        Returns:
            Optimal weights and portfolio statistics
        """
        print("üéØ Running Mean-Variance Optimization...")
        
        n_assets = len(expected_returns)
        
        # Objective: Maximize risk-adjusted returns (Sharpe-like)
        def objective(weights):
            portfolio_return = np.dot(weights, expected_returns)
            portfolio_variance = np.dot(weights, np.dot(cov_matrix, weights))
            # Negative because we minimize
            return -(portfolio_return - 0.5 * self.risk_aversion * portfolio_variance)
        
        # Constraints
        cons = [
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}  # Weights sum to 1
        ]
        
        # Position limits
        min_weight = constraints.get('min_weight', 0.0)
        max_weight = constraints.get('max_weight', 0.25)
        bounds = tuple((min_weight, max_weight) for _ in range(n_assets))
        
        # Initial guess: equal weights
        w0 = np.array([1.0 / n_assets] * n_assets)
        
        # Optimize
        result = minimize(
            objective,
            w0,
            method='SLSQP',
            bounds=bounds,
            constraints=cons,
            options={'maxiter': 1000}
        )
        
        if not result.success:
            print(f"‚ö†Ô∏è Optimization failed: {result.message}")
            return None
        
        optimal_weights = result.x
        
        # Calculate portfolio statistics
        portfolio_return = np.dot(optimal_weights, expected_returns)
        portfolio_variance = np.dot(optimal_weights, np.dot(cov_matrix, optimal_weights))
        portfolio_std = np.sqrt(portfolio_variance)
        sharpe_ratio = portfolio_return / portfolio_std if portfolio_std > 0 else 0
        
        return {
            'weights': optimal_weights.tolist(),
            'expected_return': float(portfolio_return * 252),  # Annualized
            'volatility': float(portfolio_std * np.sqrt(252)),  # Annualized
            'sharpe_ratio': float(sharpe_ratio * np.sqrt(252)),
            'max_drawdown_estimate': float(self._estimate_max_drawdown(optimal_weights, cov_matrix))
        }
    
    def optimize_with_cvar(
        self,
        expected_returns: np.ndarray,
        historical_returns: pd.DataFrame,
        constraints: Dict[str, Any],
        confidence_level: float = 0.95
    ) -> Dict:
        """
        Conditional Value at Risk (CVaR) optimization
        Focuses on tail risk management
        
        Args:
            confidence_level: CVaR confidence level (e.g., 0.95 = worst 5%)
        """
        print(f"üéØ Running CVaR Optimization (confidence={confidence_level})...")
        
        n_assets = len(expected_returns)
        returns_matrix = historical_returns.values
        
        def cvar_objective(weights):
            # Calculate portfolio returns
            portfolio_returns = np.dot(returns_matrix, weights)
            
            # CVaR: mean of worst (1-confidence_level) returns
            var_threshold = np.percentile(portfolio_returns, (1 - confidence_level) * 100)
            cvar = -np.mean(portfolio_returns[portfolio_returns <= var_threshold])
            
            # Balance return and CVaR
            portfolio_return = np.dot(weights, expected_returns)
            return -(portfolio_return - self.risk_aversion * cvar)
        
        # Constraints
        cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]
        
        min_weight = constraints.get('min_weight', 0.0)
        max_weight = constraints.get('max_weight', 0.25)
        bounds = tuple((min_weight, max_weight) for _ in range(n_assets))
        
        w0 = np.array([1.0 / n_assets] * n_assets)
        
        result = minimize(
            cvar_objective,
            w0,
            method='SLSQP',
            bounds=bounds,
            constraints=cons,
            options={'maxiter': 1000}
        )
        
        optimal_weights = result.x
        portfolio_returns = np.dot(returns_matrix, optimal_weights)
        var_threshold = np.percentile(portfolio_returns, (1 - confidence_level) * 100)
        cvar = -np.mean(portfolio_returns[portfolio_returns <= var_threshold])
        
        return {
            'weights': optimal_weights.tolist(),
            'expected_return': float(np.dot(optimal_weights, expected_returns) * 252),
            'cvar_95': float(cvar * np.sqrt(252)),
            'var_95': float(-var_threshold * np.sqrt(252))
        }
    
    def optimize_with_entropy(
        self,
        expected_returns: np.ndarray,
        cov_matrix: np.ndarray,
        constraints: Dict[str, Any],
        entropy_weight: float = 0.1
    ) -> Dict:
        """
        Maximum diversification with entropy regularization
        Prevents over-concentration in few assets
        """
        print("üéØ Running Entropy-Constrained Optimization...")
        
        n_assets = len(expected_returns)
        
        def entropy_objective(weights):
            # Entropy term encourages diversification
            entropy = -np.sum(weights * np.log(weights + 1e-10))
            
            portfolio_return = np.dot(weights, expected_returns)
            portfolio_variance = np.dot(weights, np.dot(cov_matrix, weights))
            
            # Combine objectives
            return -(portfolio_return - 0.5 * self.risk_aversion * portfolio_variance + entropy_weight * entropy)
        
        cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]
        
        min_weight = constraints.get('min_weight', 0.01)  # Small minimum for entropy
        max_weight = constraints.get('max_weight', 0.20)  # Lower max for diversification
        bounds = tuple((min_weight, max_weight) for _ in range(n_assets))
        
        w0 = np.array([1.0 / n_assets] * n_assets)
        
        result = minimize(
            entropy_objective,
            w0,
            method='SLSQP',
            bounds=bounds,
            constraints=cons,
            options={'maxiter': 1000}
        )
        
        optimal_weights = result.x
        
        # Calculate diversification ratio
        asset_vol = np.sqrt(np.diag(cov_matrix))
        diversification_ratio = np.dot(optimal_weights, asset_vol) / np.sqrt(np.dot(optimal_weights, np.dot(cov_matrix, optimal_weights)))
        
        return {
            'weights': optimal_weights.tolist(),
            'expected_return': float(np.dot(optimal_weights, expected_returns) * 252),
            'volatility': float(np.sqrt(np.dot(optimal_weights, np.dot(cov_matrix, optimal_weights))) * np.sqrt(252)),
            'diversification_ratio': float(diversification_ratio),
            'effective_n_assets': float(1.0 / np.sum(optimal_weights ** 2))
        }
    
    def _estimate_max_drawdown(self, weights: np.ndarray, cov_matrix: np.ndarray) -> float:
        """Estimate maximum drawdown using Cornish-Fisher approximation"""
        portfolio_std = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights)))
        # Rough approximation: MDD ~= 2 * sqrt(2) * volatility (for normal returns)
        return 2.828 * portfolio_std
    
    def compare_strategies(
        self,
        historical_returns: pd.DataFrame,
        symbols: List[str],
        ml_predictions: Optional[Dict] = None
    ) -> Dict:
        """
        Compare different optimization strategies
        
        Returns:
            Dict with results from all strategies
        """
        print("üîç Comparing optimization strategies...")
        
        # Prepare inputs
        expected_returns = self.estimate_expected_returns(historical_returns, ml_predictions)
        cov_matrix = self.estimate_covariance_matrix(historical_returns)
        
        constraints = {
            'min_weight': 0.0,
            'max_weight': 0.25
        }
        
        results = {}
        
        # 1. Mean-Variance
        results['mean_variance'] = self.optimize_mean_variance(expected_returns, cov_matrix, constraints)
        
        # 2. CVaR
        results['cvar'] = self.optimize_with_cvar(expected_returns, historical_returns, constraints)
        
        # 3. Entropy-constrained
        results['entropy'] = self.optimize_with_entropy(expected_returns, cov_matrix, constraints)
        
        # Add symbol mapping
        for strategy, result in results.items():
            if result:
                result['allocation'] = dict(zip(symbols, result['weights']))
        
        return results
    
    def save(self, path: str):
        """Save optimization parameters"""
        model_data = {
            'risk_aversion': self.risk_aversion,
            'expected_returns': self.expected_returns.tolist() if self.expected_returns is not None else None,
            'covariance_matrix': self.covariance_matrix.tolist() if self.covariance_matrix is not None else None
        }
        joblib.dump(model_data, path)
        print(f"üíæ Optimizer saved to {path}")


def main():
    parser = argparse.ArgumentParser(description='ML-Enhanced Portfolio Optimization')
    parser.add_argument('--data', required=True, help='Path to portfolio data JSON')
    parser.add_argument('--output', required=True, help='Output directory')
    parser.add_argument('--risk-aversion', type=float, default=2.5, help='Risk aversion coefficient')
    
    args = parser.parse_args()
    
    # Load data
    with open(args.data, 'r') as f:
        portfolio_data = json.load(f)
    
    print(f"üìö Loaded portfolio data")
    
    # Extract returns matrix
    returns_df = pd.DataFrame({
        item['symbol']: item['returns'] 
        for item in portfolio_data
    })
    symbols = list(returns_df.columns)
    
    # Optimize
    optimizer = MLPortfolioOptimizer(risk_aversion=args.risk_aversion)
    results = optimizer.compare_strategies(returns_df, symbols)
    
    # Save
    model_path = os.path.join(args.output, 'portfolio_optimizer.joblib')
    optimizer.save(model_path)
    
    results_path = os.path.join(args.output, 'optimization_results.json')
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"‚úÖ Optimization complete!")
    print(json.dumps(results, indent=2))


if __name__ == '__main__':
    main()
