#cloud-config
# Harvey Backend - Cloud-Init Deployment Script
# This script automatically deploys Harvey when VM starts/restarts

# IMPORTANT: Replace ALL <YOUR_*> placeholders with actual values from Replit Secrets!

package_upgrade: true
package_reboot_if_required: false

packages:
  - python3.11
  - python3.11-venv
  - python3-pip
  - freetds-dev
  - freetds-bin
  - unixodbc
  - unixodbc-dev
  - nginx
  - certbot
  - python3-certbot-nginx
  - git
  - curl
  - wget
  - htop

write_files:
  # FreeTDS Configuration
  - path: /etc/freetds/freetds.conf
    content: |
      [global]
      tds version = 7.4
      client charset = UTF-8
    permissions: '0644'

  # ODBC Driver Configuration
  - path: /etc/odbcinst.ini
    content: |
      [FreeTDS]
      Description = FreeTDS Driver
      Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so
      Setup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so
    permissions: '0644'

  # Harvey Environment Variables (.env)
  # ⚠️ IMPORTANT: Replace <YOUR_*> with actual values!
  - path: /opt/harvey-backend/.env
    content: |
      HARVEY_AI_API_KEY=<YOUR_HARVEY_AI_API_KEY>
      SQLSERVER_HOST=<YOUR_SQLSERVER_HOST>
      SQLSERVER_DB=<YOUR_SQLSERVER_DB>
      SQLSERVER_USER=<YOUR_SQLSERVER_USER>
      SQLSERVER_PASSWORD=<YOUR_SQLSERVER_PASSWORD>
      OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>
      ML_API_BASE_URL=http://127.0.0.1:9000/api/internal/ml
      INTERNAL_ML_API_KEY=<YOUR_INTERNAL_ML_API_KEY>
      ODBCSYSINI=/etc
      ENVIRONMENT=production
    permissions: '0600'
    owner: azureuser:azureuser

  # Harvey Systemd Service
  - path: /etc/systemd/system/harvey.service
    content: |
      [Unit]
      Description=Harvey AI Financial Advisor Backend
      After=network.target

      [Service]
      Type=simple
      User=azureuser
      Group=azureuser
      WorkingDirectory=/opt/harvey-backend
      Environment="PATH=/opt/harvey-backend/venv/bin"
      Environment="ODBCSYSINI=/etc"
      ExecStart=/opt/harvey-backend/venv/bin/uvicorn main:app --host 127.0.0.1 --port 8000 --workers 4
      Restart=always
      RestartSec=10
      StandardOutput=append:/var/log/harvey/access.log
      StandardError=append:/var/log/harvey/error.log

      [Install]
      WantedBy=multi-user.target
    permissions: '0644'

  # ML API Systemd Service
  - path: /etc/systemd/system/ml-api.service
    content: |
      [Unit]
      Description=Harvey ML Prediction API
      After=network.target

      [Service]
      Type=simple
      User=azureuser
      Group=azureuser
      WorkingDirectory=/home/azureuser/ml-api
      Environment="PATH=/home/azureuser/ml-api/venv/bin"
      ExecStart=/home/azureuser/ml-api/venv/bin/uvicorn main:app --host 127.0.0.1 --port 9000 --workers 2
      Restart=always
      RestartSec=10
      StandardOutput=append:/var/log/ml-api/access.log
      StandardError=append:/var/log/ml-api/error.log

      [Install]
      WantedBy=multi-user.target
    permissions: '0644'

  # Nginx Configuration
  - path: /etc/nginx/sites-available/harvey
    content: |
      upstream harvey_backend {
          server 127.0.0.1:8000;
      }

      upstream ml_api {
          server 127.0.0.1:9000;
      }

      server {
          listen 80;
          server_name _;

          # Increase timeouts for ML API
          proxy_read_timeout 300s;
          proxy_connect_timeout 300s;
          proxy_send_timeout 300s;

          # Harvey Backend API
          location / {
              proxy_pass http://harvey_backend;
              proxy_http_version 1.1;
              proxy_set_header Upgrade $http_upgrade;
              proxy_set_header Connection 'upgrade';
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $scheme;
              proxy_cache_bypass $http_upgrade;
              
              # CORS headers
              add_header 'Access-Control-Allow-Origin' '*' always;
              add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE' always;
              add_header 'Access-Control-Allow-Headers' 'Authorization, Content-Type' always;
          }

          # ML API Routes
          location /api/internal/ml/ {
              proxy_pass http://ml_api;
              proxy_http_version 1.1;
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $scheme;
          }

          # Increase client body size for file uploads
          client_max_body_size 50M;

          # Logging
          access_log /var/log/nginx/harvey_access.log;
          error_log /var/log/nginx/harvey_error.log;
      }
    permissions: '0644'

  # Harvey Deployment Script (downloads code from Replit)
  - path: /tmp/deploy-harvey.sh
    content: |
      #!/bin/bash
      set -e
      
      echo "======================================"
      echo "Harvey Backend - Cloud-Init Deployment"
      echo "======================================"
      
      # Create directories
      mkdir -p /opt/harvey-backend
      mkdir -p /var/log/harvey
      mkdir -p /var/log/ml-api
      chown -R azureuser:azureuser /opt/harvey-backend /var/log/harvey /var/log/ml-api
      
      # Download Harvey code from Replit (or use tar file if available)
      cd /opt/harvey-backend
      
      # Option 1: If you uploaded harvey-backend.tar.gz to /tmp/
      if [ -f "/tmp/harvey-backend.tar.gz" ]; then
          echo "Found harvey-backend.tar.gz, extracting..."
          tar -xzf /tmp/harvey-backend.tar.gz
      else
          echo "⚠️  harvey-backend.tar.gz not found!"
          echo "Please upload harvey-backend.tar.gz to /tmp/ before running cloud-init"
          echo "Or clone from Git repository if available"
          # Uncomment and update if you have a Git repo:
          # git clone https://github.com/your-org/harvey-backend.git .
          exit 1
      fi
      
      # Create Python virtual environment
      python3.11 -m venv venv
      source venv/bin/activate
      
      # Install Python dependencies
      pip install --upgrade pip setuptools wheel
      pip install -r requirements.txt
      
      # Test database connection
      echo "Testing database connection..."
      python3 -c "
import os
from dotenv import load_dotenv
load_dotenv()
import pyodbc

conn_str = (
    f\"DRIVER={{FreeTDS}};\"
    f\"SERVER={os.getenv('SQLSERVER_HOST')};\"
    f\"DATABASE={os.getenv('SQLSERVER_DB')};\"
    f\"UID={os.getenv('SQLSERVER_USER')};\"
    f\"PWD={os.getenv('SQLSERVER_PASSWORD')};\"
    f\"TDS_Version=7.4;\"
    f\"Port=1433;\"
)

try:
    conn = pyodbc.connect(conn_str, timeout=10)
    print('✅ Database connection successful!')
    conn.close()
except Exception as e:
    print(f'⚠️  Database connection failed: {e}')
    print('Harvey will start but database queries may fail.')
"
      
      # Enable Nginx site
      ln -sf /etc/nginx/sites-available/harvey /etc/nginx/sites-enabled/
      rm -f /etc/nginx/sites-enabled/default
      
      # Test Nginx configuration
      nginx -t
      
      # Reload systemd
      systemctl daemon-reload
      
      # Enable and start services
      systemctl enable harvey.service
      systemctl enable ml-api.service
      systemctl enable nginx
      
      systemctl restart harvey.service || echo "⚠️  Harvey service failed to start"
      systemctl restart ml-api.service || echo "⚠️  ML API service failed to start"
      systemctl restart nginx || echo "⚠️  Nginx failed to start"
      
      # Wait for services to start
      sleep 5
      
      # Health checks
      echo ""
      echo "Running health checks..."
      curl -s http://127.0.0.1:8000/ > /dev/null && echo "✅ Harvey backend OK" || echo "❌ Harvey backend failed"
      curl -s http://127.0.0.1:9000/health > /dev/null && echo "✅ ML API OK" || echo "❌ ML API failed"
      curl -s http://127.0.0.1/ > /dev/null && echo "✅ Nginx OK" || echo "❌ Nginx failed"
      
      echo ""
      echo "======================================"
      echo "✅ Harvey Deployment Complete!"
      echo "======================================"
      echo "Access Harvey at: http://$(curl -s ifconfig.me)/"
      echo ""
      echo "View logs:"
      echo "  Harvey: journalctl -u harvey.service -f"
      echo "  ML API: journalctl -u ml-api.service -f"
      echo "  Nginx: tail -f /var/log/nginx/harvey_error.log"
      
    permissions: '0755'

runcmd:
  # Configure UFW firewall
  - ufw --force enable
  - ufw allow 22/tcp
  - ufw allow 80/tcp
  - ufw allow 443/tcp
  - ufw delete allow 9000/tcp || true

  # Run Harvey deployment script
  - bash /tmp/deploy-harvey.sh

final_message: |
  ====================================
  Harvey Backend - Cloud-Init Complete
  ====================================
  
  Harvey should now be running!
  
  Access at: http://YOUR_VM_PUBLIC_IP/
  
  Check status:
    sudo systemctl status harvey.service
    sudo systemctl status ml-api.service
    sudo systemctl status nginx
  
  View logs:
    sudo journalctl -u harvey.service -f
