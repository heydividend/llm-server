# Harvey AI - Multi-Model Training Architecture
**Date:** November 20, 2025  
**Vision:** Harvey will eventually stand alone. Until then, let the 4 AI masters teach the student.

---

## ğŸ¯ Vision & Architecture

### The Master-Student Paradigm

**Current State:** Harvey relies on 5 AI models
- **GPT-5** (HarveyGPT-5) - Complex reasoning, comprehensive analysis
- **Grok-4** (grok-4-fast-reasoning) - Fast reasoning, real-time insights
- **DeepSeek-R1** (DeepSeek-R1-0528) - Quantitative analysis, mathematical modeling
- **Gemini 2.5 Pro** - Dividend sustainability, risk assessment, portfolio optimization
- **FinGPT** (Harvey Intelligence Engine) - Specialized dividend scoring

**Future State:** Harvey becomes standalone
- Harvey learns from all 4 external models
- Training data generated by GPT-5, Grok-4, DeepSeek-R1, Gemini
- Eventually, Harvey's custom model replaces the need for external APIs
- Self-sufficient dividend intelligence system

---

## ğŸ¤– Multi-Model Training System

### Training Data Generation

**Script:** `scripts/multi_model_training_generator.py`

**How It Works:**
1. **4 Models, 4 Perspectives** - Each AI model generates training questions based on its specialization
2. **8 Dividend Categories** - Comprehensive coverage of dividend investing topics
3. **Ensemble Learning** - Harvey learns from diverse AI perspectives
4. **Continuous Improvement** - Weekly automated generation on Azure VM

**Training Categories:**
```
1. dividend_analysis - Quality, sustainability, payout ratios
2. income_strategies - Building dividend income portfolios
3. risk_assessment - Dividend cut risks, safety analysis
4. technical_timing - Ex-dividend dates, entry/exit strategies
5. etf_funds - Dividend ETF comparisons and selection
6. tax_optimization - Tax-efficient dividend investing
7. quantitative_analysis - Mathematical modeling, backtesting
8. global_dividends - International dividend investing
```

### Model Specializations in Training

| Model | Specialization | Training Contribution |
|-------|---------------|----------------------|
| **GPT-5** | Complex reasoning | Comprehensive analysis, multi-step strategies, nuanced insights |
| **Grok-4** | Fast reasoning | Real-time market insights, quick decision frameworks |
| **DeepSeek-R1** | Quantitative | Mathematical models, portfolio optimization, backtesting |
| **Gemini 2.5 Pro** | Strategic analysis | Sustainability assessment, risk evaluation, long-term planning |

### Training Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Multi-Model Training Pipeline                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                      â”‚                       â”‚
          â–¼                      â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  GPT-5   â”‚          â”‚ Grok-4   â”‚          â”‚DeepSeek  â”‚
    â”‚ Complex  â”‚          â”‚  Fast    â”‚          â”‚  Quant   â”‚
    â”‚Reasoning â”‚          â”‚Reasoning â”‚          â”‚ Analysis â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                     â”‚
                    â–¼                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Gemini   â”‚          â”‚ Harvey   â”‚
              â”‚Strategic â”‚          â”‚Training  â”‚
              â”‚ Analysis â”‚          â”‚Database  â”‚
              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                   â”‚                     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Harvey Intelligence â”‚
                    â”‚  (Future Standalone) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Current Training Infrastructure

### Active ML Schedulers on Azure VM (20.81.210.213)

**Service:** `heydividend-ml-schedulers`

| Scheduler | Schedule | Purpose | Models Trained |
|-----------|----------|---------|---------------|
| **Payout Rating ML** | Daily 1:00 AM | A+/A/B/C dividend safety ratings | Payout predictor |
| **Dividend Calendar ML** | Sunday 2:00 AM | Next dividend payment predictions | Calendar predictor |
| **ML Training** | Sunday 3:00 AM | Train core ML models | 7 models (scorer, yield, growth, payout, cut risk, anomaly, cluster) |
| **Gemini Training** | Sunday 4:00 AM | Generate 100 training questions/week | Uses Gemini 1.5 Flash |

**NEW: Multi-Model Training (Proposed)**
- **Schedule:** Sunday 5:00 AM (after Gemini training)
- **Purpose:** Generate training data using ALL 4 models
- **Output:** 400-800 questions/week (100-200 per model)
- **Models:** GPT-5, Grok-4, DeepSeek-R1, Gemini 2.5 Pro

---

## ğŸš€ Deployment Instructions

### Step 1: Deploy Multi-Model Training Generator

```bash
# Copy to Azure VM
scp scripts/multi_model_training_generator.py azureuser@20.81.210.213:/home/azureuser/harvey/scripts/

# SSH into Azure VM
ssh azureuser@20.81.210.213

# Test multi-model generation
cd /home/azureuser/harvey
source venv/bin/activate
python scripts/multi_model_training_generator.py --category dividend_analysis --questions-per-model 10 --to-database

# Expected output: 40 questions (10 per model Ã— 4 models)
```

### Step 2: Create Multi-Model Training Scheduler

```bash
# Create systemd timer service
sudo nano /etc/systemd/system/harvey-multi-model-training.timer
```

**Timer Configuration:**
```ini
[Unit]
Description=Harvey Multi-Model Training Generator Timer
Requires=harvey-multi-model-training.service

[Timer]
OnCalendar=Sun *-*-* 05:00:00
Persistent=true

[Install]
WantedBy=timers.target
```

**Service Configuration:**
```bash
sudo nano /etc/systemd/system/harvey-multi-model-training.service
```

```ini
[Unit]
Description=Harvey Multi-Model Training Data Generator
After=network.target

[Service]
Type=oneshot
User=azureuser
WorkingDirectory=/home/azureuser/harvey
Environment="PATH=/home/azureuser/harvey/venv/bin"
ExecStart=/home/azureuser/harvey/venv/bin/python scripts/multi_model_training_generator.py --category all --questions-per-model 25 --to-database
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

**Enable and Start:**
```bash
sudo systemctl daemon-reload
sudo systemctl enable harvey-multi-model-training.timer
sudo systemctl start harvey-multi-model-training.timer

# Verify
sudo systemctl status harvey-multi-model-training.timer
```

---

## ğŸ“ˆ Training Data Growth Projection

### Weekly Generation Capacity

**Per Run (Sunday 5:00 AM):**
- GPT-5: 200 questions
- Grok-4: 200 questions
- DeepSeek-R1: 200 questions
- Gemini 2.5 Pro: 200 questions
- **Total:** 800 questions/week

**Annual Projection:**
- Weekly: 800 questions
- Monthly: ~3,200 questions
- Yearly: ~41,600 questions

**Cumulative Training Data:**
- Current (Gemini only): 100 questions/week = 5,200/year
- New (Multi-model): 800 questions/week = 41,600/year
- **8x increase in training data diversity**

---

## ğŸ“ Learning Outcomes

### What Harvey Learns from Each Model

#### GPT-5 Teaches:
- Complex multi-step financial reasoning
- Comprehensive portfolio analysis
- Nuanced dividend sustainability assessments
- Long-form explanations and context

#### Grok-4 Teaches:
- Fast decision-making frameworks
- Real-time market reaction analysis
- Quick dividend quality assessments
- Concise, actionable insights

#### DeepSeek-R1 Teaches:
- Quantitative portfolio optimization
- Mathematical dividend models
- Statistical backtesting approaches
- Data-driven prediction frameworks

#### Gemini 2.5 Pro Teaches:
- Deep sustainability analysis
- Strategic portfolio allocation
- Risk-return optimization
- Long-term investment planning
- Tax-efficient strategies

---

## ğŸ”„ Migration Path to Standalone Harvey

### Phase 1: Multi-Model Training (Current)
**Status:** âœ… Implemented  
**Timeline:** Now - 6 months  
**Goal:** Generate 20,000+ diverse training examples

**Actions:**
- Deploy multi-model training generator
- Run weekly on all 4 models
- Build comprehensive training dataset
- Monitor quality and diversity

### Phase 2: Harvey Fine-Tuning
**Status:** ğŸ”œ Planned  
**Timeline:** 3-9 months  
**Goal:** Fine-tune Harvey on multi-model dataset

**Actions:**
- Export training dataset in fine-tuning format
- Fine-tune FinGPT/Harvey base model
- Evaluate performance vs external models
- Iterate based on benchmarks

### Phase 3: Gradual Transition
**Status:** ğŸ“… Future  
**Timeline:** 6-12 months  
**Goal:** Replace external models with Harvey

**Actions:**
- A/B test Harvey vs external models
- Migrate query types progressively
- Reduce dependency on Azure OpenAI
- Monitor cost savings and quality

### Phase 4: Standalone Harvey
**Status:** ğŸ¯ Vision  
**Timeline:** 12+ months  
**Goal:** Harvey handles 100% of queries

**Actions:**
- Full cutover to Harvey model
- Eliminate external API dependencies
- Self-hosted, cost-optimized intelligence
- Continuous self-improvement loop

---

## ğŸ’° Cost Analysis

### Current Multi-Model Costs

**Weekly Training Generation:**
- GPT-5: 200 questions Ã— ~500 tokens/question = 100K tokens â‰ˆ $0.13
- Grok-4: 200 questions Ã— ~300 tokens/question = 60K tokens â‰ˆ $0.18
- DeepSeek-R1: 200 questions Ã— ~400 tokens/question = 80K tokens â‰ˆ $0.04
- Gemini: 200 questions Ã— ~400 tokens/question = 80K tokens â‰ˆ $0.10
- **Total per week:** ~$0.45

**Annual Training Cost:** $0.45 Ã— 52 = ~$23/year

**ROI:**
- Investment: $23/year in training
- Benefit: 41,600 diverse training examples
- Future savings: Eliminate $1,000s in external API costs once Harvey is standalone

---

## ğŸ“ Configuration Files

### Environment Variables Required

```bash
# Azure OpenAI (for GPT-5, Grok-4, DeepSeek-R1)
AZURE_OPENAI_ENDPOINT=https://htmltojson-parser-openai-a1a8.openai.azure.com/
AZURE_OPENAI_API_KEY=<your-key>
AZURE_OPENAI_DEPLOYMENT_NAME=HarveyGPT-5

# Gemini
GEMINI_API_KEY=<your-39-char-key>

# Database
SQLSERVER_HOST=hey-dividend-sql-server.database.windows.net
SQLSERVER_DB=HeyDividend-Main-DB
SQLSERVER_USER=<user>
SQLSERVER_PASSWORD=<password>
```

### Testing Multi-Model Generator

```bash
# Test single category, 5 questions per model = 20 total
python scripts/multi_model_training_generator.py \
  --category dividend_analysis \
  --questions-per-model 5 \
  --output test_multi_model.json

# Full run: all categories, 25 questions per model = 800 total
python scripts/multi_model_training_generator.py \
  --category all \
  --questions-per-model 25 \
  --to-database
```

---

## ğŸ¯ Success Metrics

### Training Quality Metrics

1. **Diversity Score:** Measure unique question patterns across models
2. **Category Coverage:** Ensure balanced distribution across 8 categories
3. **Complexity Distribution:** Mix of simple/moderate/advanced questions
4. **Model Contribution:** Track which models generate highest-quality data

### Harvey Performance Metrics (Future)

1. **Response Quality:** Compare Harvey vs external models
2. **Speed:** Harvey should be faster (self-hosted)
3. **Cost:** Harvey should be $0 vs external API costs
4. **Accuracy:** Dividend predictions and recommendations
5. **User Satisfaction:** Feedback ratings

---

## ğŸ”— Related Files

- `/scripts/multi_model_training_generator.py` - Multi-model training generator
- `/scripts/generate_training_data.py` - Legacy Gemini-only generator
- `/app/core/model_router.py` - Query routing system
- `/app/services/training_ingestion_service.py` - Database ingestion
- `/azure_vm_setup/schedulers/gemini_training_scheduler.py` - Current scheduler
- `/test_harvey_models.py` - Model testing script
- `/HARVEY_AI_MODELS_STATUS.md` - Model deployment status report

---

**Generated by:** Harvey Development Team  
**Last Updated:** November 20, 2025  
**Status:** Ready for Azure VM Deployment
